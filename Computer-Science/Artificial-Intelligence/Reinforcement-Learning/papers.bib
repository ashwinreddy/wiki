@misc{pong2020skewfit,
      title={Skew-Fit: State-Covering Self-Supervised Reinforcement Learning}, 
      author={Vitchyr H. Pong and Murtaza Dalal and Steven Lin and Ashvin Nair and Shikhar Bahl and Sergey Levine},
      year={2020},
      eprint={1903.03698},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{spinup,
title = {Intro to Policy Optimization},
howpublished = {\url{https://spinningup.openai.com/en/latest/spinningup/rl_intro3.html}},
year = 2018
}

@misc{hartikainen2019dynamical,
    title={Dynamical Distance Learning for Semi-Supervised and Unsupervised Skill Discovery},
    author={Kristian Hartikainen and Xinyang Geng and Tuomas Haarnoja and Sergey Levine},
    year={2019},
    eprint={1907.08225},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{fujimoto2018addressing,
    title={Addressing Function Approximation Error in Actor-Critic Methods},
    author={Scott Fujimoto and Herke van Hoof and David Meger},
    year={2018},
    eprint={1802.09477},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}

@misc{levine2018reinforcement,
    title={Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review},
    author={Sergey Levine},
    year={2018},
    eprint={1805.00909},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{kakade2002natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  booktitle={Advances in neural information processing systems},
  pages={1531--1538},
  year={2002}
}

@misc{fu2018variational,
    title={Variational Inverse Control with Events: A General Framework for Data-Driven Reward Definition},
    author={Justin Fu and Avi Singh and Dibya Ghosh and Larry Yang and Sergey Levine},
    year={2018},
    eprint={1805.11686},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{peng2019advantageweighted,
    title={Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning},
    author={Xue Bin Peng and Aviral Kumar and Grace Zhang and Sergey Levine},
    year={2019},
    eprint={1910.00177},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{burda2018exploration,
    title={Exploration by Random Network Distillation},
    author={Yuri Burda and Harrison Edwards and Amos Storkey and Oleg Klimov},
    year={2018},
    eprint={1810.12894},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{kumar2020conservative,
    title={Conservative Q-Learning for Offline Reinforcement Learning},
    author={Aviral Kumar and Aurick Zhou and George Tucker and Sergey Levine},
    year={2020},
    eprint={2006.04779},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{lillicrap2015continuous,
    title={Continuous control with deep reinforcement learning},
    author={Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
    year={2015},
    eprint={1509.02971},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{nair2020accelerating,
    title={Accelerating Online Reinforcement Learning with Offline Datasets},
    author={Ashvin Nair and Murtaza Dalal and Abhishek Gupta and Sergey Levine},
    year={2020},
    eprint={2006.09359},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{haarnoja2018soft,
    title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
    author={Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine},
    year={2018},
    eprint={1801.01290},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{levine2020offline,
    title={Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems},
    author={Sergey Levine and Aviral Kumar and George Tucker and Justin Fu},
    year={2020},
    eprint={2005.01643},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{10.5555/3044805.3044850,
author = {Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
title = {Deterministic Policy Gradient Algorithms},
year = {2014},
publisher = {JMLR.org},
booktitle = {Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32},
pages = {I–387–I–395},
numpages = {9},
location = {Beijing, China},
series = {ICML’14}
}
  
