The entropy of a random variable is the number of bits needed to describe it.

$$
H(X) = \mathbb{E}_{x \sim X}[I_X(x)]
$$

$$
H(X) = -\sum_i p_i \lg p_i
$$
