The **entropy** of a random variable $X$ is defined as

\begin{equation}
H(X) \equiv \mathbb{E}\left[\log\frac{1}{\Pr(x)}\right]
\end{equation}

Intuitively, the entropy returns the number of bits needed to characterize the random variable.