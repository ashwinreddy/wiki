The **mutual information** between [[random variables|random variable]] $X$ and $Y$ is given by measuring how inefficient it is to pretend that $X$ and $Y$ are totally independent.

$$
I(X ; Y ) = D_{KL}( p_{(X, Y)} \parallel p_X p_Y )
$$