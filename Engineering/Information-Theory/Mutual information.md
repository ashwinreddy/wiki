The **mutual information** between [[random variables|random variable]] $X$ and $Y$ is given by measuring how inefficient it is to pretend that $X$ and $Y$ are totally independent. Two variables have no mutual information, then, if they are independent.

\begin{equation}
I(X ; Y ) = D_{KL}( p_{(X, Y)} \parallel p_X p_Y )
\end{equation}