**Source coding theorem** says you cannot compress $X$ in less than $H(X)$ bits.

> Consider $N$ [[iid]] [[random variable]] each with entropy $H(X)$. This can be compressed into no more than $NH(X)$ bits with negligble risk of information loss as $N \to \infty$. Conversely, if they are compressed into fewer than $NH(X)$ bits, it is virtually certain that information will be lost.