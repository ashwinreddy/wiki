The **Kullback-Leibler (KL) divergence** measures the difference between two distributions, one of which is assumed to be a "true" distribution using [[entropy]].

$$
D_{KL}(P \parallel Q) = H(P,Q) - H(P)
$$