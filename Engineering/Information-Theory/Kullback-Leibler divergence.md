The **Kullback-Leibler (KL) divergence** is a measure of inefficiency in using a distribution $Q$ to model distribution $P$.

$$
D_{KL} (P \parallel Q) = H(P, Q) - H(P)
$$

$$
D_{KL}(P \parallel Q) = \mathbb{E}_{x \sim P}\left[\right]
$$