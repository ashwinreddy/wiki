The **Hessian matrix** of a [[function]] $f: \RR^n \to \RR$ is like the [[Jacobian]] of the [[gradient]], yielding a [[square matrix]] where each entry is a second [[derivative]] of $f$.

$$
H_{ij} = \frac{\partial^2 f}{\partial x_i \partial x_j}
$$

For example, for the [[quadratic form]] $x^\mathsf{T}Ax$, the Hessian is exactly $A$. Otherwise, it's the best choice of $A$ at a point for the function.