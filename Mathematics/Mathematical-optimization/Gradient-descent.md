**Gradient descent** is an iterative optimization algorithm for finding the minimum of a function. For a multivariable function $F(x)$, gradient descent tells us to repeat the following step until convergence:

\\[
x_{n+1} \leftarrow x_{n} - \alpha \nabla F(x_{n})
\\]