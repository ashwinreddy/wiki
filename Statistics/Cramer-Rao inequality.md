The **Cramer-Rao inequality** or **Cramer-Rao Lower Bound (CRLB)** that the MSE of any unbiased estimator ([[variance]]) is at least the reciprocal [[Fisher information]].

\begin{equation}
\boxed{\sigma^2_\theta \geq \frac{1}{ \mathcal{I}(\theta)}}
\end{equation}

Thus, high Fisher information means the possibility of a lower variance estimator.

Another way of saying this is that efficiency is maxed at 1.

\begin{equation}
{I(\theta)^{-1} \over \sigma^2_\theta} \equiv e \leq 1
\end{equation}