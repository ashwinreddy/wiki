**Entropy** is a measure of uncertainty in a [[random variable]] by its [[expected value]] of information.

$$
H[X] = \mathbb{E}\left[h(x)\right]
$$

$$
H(X) = - \sum_{x \in \chi} p(x) \log p(x)
$$