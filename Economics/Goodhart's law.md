**Goodhart's law**

> When a measure becomes a target, it ceases to be a good measure

This is basically the effect of reward hacking.